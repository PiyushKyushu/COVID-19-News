{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import os\n",
    "import tensorflow_datasets as tfds\n",
    "from tqdm import tqdm\n",
    "from transformers import RobertaTokenizer, TFRobertaForSequenceClassification\n",
    "tokenizer = RobertaTokenizer.from_pretrained('roberta-base')\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.callbacks import EarlyStopping,ModelCheckpoint\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "import nlpaug.augmenter.word as naw\n",
    "import nlpaug.augmenter.sentence as nas\n",
    "from sklearn.model_selection import train_test_split\n",
    "print(\"Hello\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10727, 5)\n",
      "(10677, 5)\n",
      "(50, 5)\n"
     ]
    }
   ],
   "source": [
    "train_df=pd.read_csv(\"All_Label_Covid_Headlines.csv\")\n",
    "print(train_df.shape)\n",
    "train_df,test_df=train_test_split(train_df,test_size=50,shuffle=True,random_state=0)\n",
    "print(train_df.shape)\n",
    "print(test_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1    5345\n",
      "0    5332\n",
      "Name: Sentiment, dtype: int64\n",
      "[1.00121905 0.99878391]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/piyushghasiya/opt/anaconda3/envs/TF2/lib/python3.7/site-packages/sklearn/utils/validation.py:70: FutureWarning: Pass classes=[0, 1], y=10515    0\n",
      "9840     0\n",
      "1454     0\n",
      "7224     1\n",
      "9116     0\n",
      "        ..\n",
      "9225     0\n",
      "4859     0\n",
      "3264     1\n",
      "9845     0\n",
      "2732     1\n",
      "Name: Sentiment, Length: 10677, dtype: int64 as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "print(train_df.Sentiment.value_counts())\n",
    "print(compute_class_weight('balanced',[0,1],train_df.Sentiment))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_example_to_feature(x):\n",
    "    \n",
    "    length=len(x)\n",
    "    threshold=int(0.3*length)\n",
    "    x=x[-threshold:]+\" \"+x\n",
    "    bert_input = tokenizer.encode_plus(\n",
    "                        x,                      \n",
    "                        add_special_tokens = True,\n",
    "                        max_length = 300,\n",
    "                        pad_to_max_length = True,\n",
    "                        return_attention_mask = True)\n",
    "    return bert_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_example_to_dict(input_ids, attention_masks, Sentiment):\n",
    "    return {\n",
    "      \"input_ids\": input_ids,\n",
    "      \"attention_mask\": attention_masks\n",
    "    }, Sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_dataset = (\n",
    "    tf.data.Dataset.from_tensor_slices(\n",
    "        (\n",
    "            tf.cast(train_df['Headline_Clean'].values, tf.string),\n",
    "            tf.cast(train_df['Sentiment'].values, tf.int32)\n",
    "        )\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = (\n",
    "    tf.data.Dataset.from_tensor_slices(\n",
    "        (\n",
    "            tf.cast(test_df['Headline_Clean'].values, tf.string),\n",
    "            tf.cast(test_df['Sentiment'].values, tf.int32)\n",
    "        )\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_examples(ds, limit=-1):\n",
    "  # prepare list, so that we can build up final TensorFlow dataset from slices.\n",
    "  input_ids_list = []\n",
    "  attention_mask_list = []\n",
    "  label_list = []\n",
    "  if (limit > 0):\n",
    "      ds = ds.take(limit)\n",
    "    \n",
    "  for Headline, Sentiment in tqdm(tfds.as_numpy(ds)):\n",
    "    bert_input = convert_example_to_feature(Headline.decode())\n",
    "  \n",
    "    input_ids_list.append(bert_input['input_ids'])\n",
    "    attention_mask_list.append(bert_input['attention_mask'])\n",
    "    label_list.append([Sentiment])\n",
    "  return tf.data.Dataset.from_tensor_slices((input_ids_list, attention_mask_list,label_list)).map(map_example_to_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/Users/piyushghasiya/opt/anaconda3/envs/TF2/lib/python3.7/site-packages/transformers/tokenization_utils_base.py:1944: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  FutureWarning,\n",
      "50it [00:00, 424.50it/s]\n"
     ]
    }
   ],
   "source": [
    "test_ds = encode_examples(test_dataset).batch(16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10677it [00:09, 1153.60it/s]\n"
     ]
    }
   ],
   "source": [
    "train_ds = encode_examples(training_dataset).shuffle(10000).batch(16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at roberta-base were not used when initializing TFRobertaForSequenceClassification: ['lm_head']\n",
      "- This IS expected if you are initializing TFRobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
      "- This IS NOT expected if you are initializing TFRobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some layers of TFRobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = TFRobertaForSequenceClassification.from_pretrained('roberta-base')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 1e-5\n",
    "number_of_epochs = 3\n",
    "optimizer = tf.keras.optimizers.Nadam(learning_rate=learning_rate)\n",
    "\n",
    "\n",
    "loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "metric = tf.keras.metrics.SparseCategoricalAccuracy('accuracy')\n",
    "\n",
    "early=EarlyStopping(monitor='val_accuracy',\n",
    "                              min_delta=0,\n",
    "                              patience=3,\n",
    "                              verbose=1, mode='auto')\n",
    "checkpoint=ModelCheckpoint(\n",
    "    \"/Users/piyushghasiya/PycharmProjects/News/checkpoint-{epoch:02d}-{val_accuracy:.4f}.h5\", monitor='val_accuracy', verbose=1, save_best_only=True,\n",
    "    save_weights_only=False, mode='auto', save_freq='epoch')\n",
    "\n",
    "model.compile(optimizer=optimizer, loss=loss, metrics=metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RobertaConfig {\n",
       "  \"_name_or_path\": \"roberta-base\",\n",
       "  \"architectures\": [\n",
       "    \"RobertaForMaskedLM\"\n",
       "  ],\n",
       "  \"attention_probs_dropout_prob\": 0.1,\n",
       "  \"bos_token_id\": 0,\n",
       "  \"eos_token_id\": 2,\n",
       "  \"gradient_checkpointing\": false,\n",
       "  \"hidden_act\": \"gelu\",\n",
       "  \"hidden_dropout_prob\": 0.1,\n",
       "  \"hidden_size\": 768,\n",
       "  \"initializer_range\": 0.02,\n",
       "  \"intermediate_size\": 3072,\n",
       "  \"layer_norm_eps\": 1e-05,\n",
       "  \"max_position_embeddings\": 514,\n",
       "  \"model_type\": \"roberta\",\n",
       "  \"num_attention_heads\": 12,\n",
       "  \"num_hidden_layers\": 12,\n",
       "  \"pad_token_id\": 1,\n",
       "  \"type_vocab_size\": 1,\n",
       "  \"vocab_size\": 50265\n",
       "}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['tf_roberta_for_sequence_classification_1/roberta/pooler/dense/kernel:0', 'tf_roberta_for_sequence_classification_1/roberta/pooler/dense/bias:0'] when minimizing the loss.\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['tf_roberta_for_sequence_classification_1/roberta/pooler/dense/kernel:0', 'tf_roberta_for_sequence_classification_1/roberta/pooler/dense/bias:0'] when minimizing the loss.\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['tf_roberta_for_sequence_classification_1/roberta/pooler/dense/kernel:0', 'tf_roberta_for_sequence_classification_1/roberta/pooler/dense/bias:0'] when minimizing the loss.\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['tf_roberta_for_sequence_classification_1/roberta/pooler/dense/kernel:0', 'tf_roberta_for_sequence_classification_1/roberta/pooler/dense/bias:0'] when minimizing the loss.\n",
      "668/668 [==============================] - ETA: 0s - loss: 0.3157 - accuracy: 0.8545 \n",
      "Epoch 00001: val_accuracy improved from -inf to 0.82000, saving model to /Users/piyushghasiya/PycharmProjects/News/checkpoint-01-0.8200.h5\n",
      "668/668 [==============================] - 37970s 57s/step - loss: 0.3157 - accuracy: 0.8545 - val_loss: 0.2290 - val_accuracy: 0.8200\n",
      "Epoch 2/3\n",
      "668/668 [==============================] - ETA: 0s - loss: 0.1734 - accuracy: 0.9292  \n",
      "Epoch 00002: val_accuracy improved from 0.82000 to 0.86000, saving model to /Users/piyushghasiya/PycharmProjects/News/checkpoint-02-0.8600.h5\n",
      "668/668 [==============================] - 40163s 60s/step - loss: 0.1734 - accuracy: 0.9292 - val_loss: 0.2991 - val_accuracy: 0.8600\n",
      "Epoch 3/3\n",
      "668/668 [==============================] - ETA: 0s - loss: 0.1223 - accuracy: 0.9508 \n",
      "Epoch 00003: val_accuracy improved from 0.86000 to 0.90000, saving model to /Users/piyushghasiya/PycharmProjects/News/checkpoint-03-0.9000.h5\n",
      "668/668 [==============================] - 37870s 57s/step - loss: 0.1223 - accuracy: 0.9508 - val_loss: 0.3374 - val_accuracy: 0.9000\n"
     ]
    }
   ],
   "source": [
    "bert_history = model.fit(train_ds, epochs=number_of_epochs, validation_data=test_ds,\n",
    "                         callbacks=[early,checkpoint],class_weight={0:1.00121905,1:0.99878391})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Month</th>\n",
       "      <th>Date</th>\n",
       "      <th>Headline</th>\n",
       "      <th>Headline_Clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>August</td>\n",
       "      <td>14 Aug 2020</td>\n",
       "      <td>Japan and Malaysia may resume travel in early ...</td>\n",
       "      <td>japan malaysia may resume travel early septemb...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>August</td>\n",
       "      <td>15 Aug 2020</td>\n",
       "      <td>Japan marks 75th surrender anniversary in sole...</td>\n",
       "      <td>japan mark surrender anniversary solemn ceremo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>August</td>\n",
       "      <td>15 Aug 2020</td>\n",
       "      <td>Indonesia to close doors to tourists until vac...</td>\n",
       "      <td>indonesia close doors tourists vaccine find</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>August</td>\n",
       "      <td>15 Aug 2020</td>\n",
       "      <td>How COVID-19 has reshaped Japan's drinking cul...</td>\n",
       "      <td>reshape japan drink culture</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>August</td>\n",
       "      <td>15 Aug 2020</td>\n",
       "      <td>COVID-19 ruins plans to spend time at the beac...</td>\n",
       "      <td>ruin plan spend time beach among things</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Month         Date                                           Headline  \\\n",
       "0  August  14 Aug 2020  Japan and Malaysia may resume travel in early ...   \n",
       "1  August  15 Aug 2020  Japan marks 75th surrender anniversary in sole...   \n",
       "2  August  15 Aug 2020  Indonesia to close doors to tourists until vac...   \n",
       "3  August  15 Aug 2020  How COVID-19 has reshaped Japan's drinking cul...   \n",
       "4  August  15 Aug 2020  COVID-19 ruins plans to spend time at the beac...   \n",
       "\n",
       "                                      Headline_Clean  \n",
       "0  japan malaysia may resume travel early septemb...  \n",
       "1  japan mark surrender anniversary solemn ceremo...  \n",
       "2        indonesia close doors tourists vaccine find  \n",
       "3                        reshape japan drink culture  \n",
       "4            ruin plan spend time beach among things  "
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv(\"Preprocessed_Headline_Japan.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/21038 [00:00<?, ?it/s]/Users/piyushghasiya/opt/anaconda3/envs/TF2/lib/python3.7/site-packages/transformers/tokenization_utils_base.py:1944: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  FutureWarning,\n",
      "100%|██████████| 21038/21038 [00:06<00:00, 3451.43it/s]\n"
     ]
    }
   ],
   "source": [
    "input_data={}\n",
    "input_data['input_ids']=[]\n",
    "# input_data['token_type_ids']=[]\n",
    "input_data['attention_mask']=[]\n",
    "\n",
    "for i in tqdm(df.Headline_Clean):\n",
    "    bert_output=convert_example_to_feature(i)\n",
    "    input_data['input_ids'].append(bert_output['input_ids'])\n",
    "#     input_data['token_type_ids'].append(bert_output['token_type_ids'])\n",
    "    input_data['attention_mask'].append(bert_output['attention_mask'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data['input_ids']=np.array(input_data['input_ids'])\n",
    "# input_data['token_type_ids']=np.array(input_data['token_type_ids'])\n",
    "input_data['attention_mask']=np.array(input_data['attention_mask'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "model.load_weights(\"/Users/piyushghasiya/PycharmProjects/News/checkpoint-03-0.9000.h5\")\n",
    "pred=model.predict(input_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_preds=np.argmax(pred[0],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Sentiment']=final_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Month</th>\n",
       "      <th>Date</th>\n",
       "      <th>Headline</th>\n",
       "      <th>Headline_Clean</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>August</td>\n",
       "      <td>14 Aug 2020</td>\n",
       "      <td>Japan and Malaysia may resume travel in early ...</td>\n",
       "      <td>japan malaysia may resume travel early septemb...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>August</td>\n",
       "      <td>15 Aug 2020</td>\n",
       "      <td>Japan marks 75th surrender anniversary in sole...</td>\n",
       "      <td>japan mark surrender anniversary solemn ceremo...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>August</td>\n",
       "      <td>15 Aug 2020</td>\n",
       "      <td>Indonesia to close doors to tourists until vac...</td>\n",
       "      <td>indonesia close doors tourists vaccine find</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>August</td>\n",
       "      <td>15 Aug 2020</td>\n",
       "      <td>How COVID-19 has reshaped Japan's drinking cul...</td>\n",
       "      <td>reshape japan drink culture</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>August</td>\n",
       "      <td>15 Aug 2020</td>\n",
       "      <td>COVID-19 ruins plans to spend time at the beac...</td>\n",
       "      <td>ruin plan spend time beach among things</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21033</th>\n",
       "      <td>September</td>\n",
       "      <td>September 9, 2020 at 16:17 JST</td>\n",
       "      <td>China's CanSino defends coronavirus vaccine ca...</td>\n",
       "      <td>china cansino defend coronavirus vaccine candi...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21034</th>\n",
       "      <td>September</td>\n",
       "      <td>September 9, 2020 at 17:15 JST</td>\n",
       "      <td>U.S. firms in China increasingly fear bilatera...</td>\n",
       "      <td>firm china increasingly fear bilateral tension...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21035</th>\n",
       "      <td>September</td>\n",
       "      <td>September 9, 2020 at 17:15 JST</td>\n",
       "      <td>South Korea president to hold emergency meetin...</td>\n",
       "      <td>south korea president hold emergency meet thur...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21036</th>\n",
       "      <td>September</td>\n",
       "      <td>September 9, 2020 at 17:18 JST</td>\n",
       "      <td>Tokyo in July sees more people moving out than...</td>\n",
       "      <td>tokyo july see people move due virus</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21037</th>\n",
       "      <td>September</td>\n",
       "      <td>September 9, 2020 at 19:04 JST</td>\n",
       "      <td>A year after Typhoon No. 15, Chiba residents s...</td>\n",
       "      <td>year typhoon no chiba residents still struggle</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>21038 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Month                            Date  \\\n",
       "0         August                     14 Aug 2020   \n",
       "1         August                     15 Aug 2020   \n",
       "2         August                     15 Aug 2020   \n",
       "3         August                     15 Aug 2020   \n",
       "4         August                     15 Aug 2020   \n",
       "...          ...                             ...   \n",
       "21033  September  September 9, 2020 at 16:17 JST   \n",
       "21034  September  September 9, 2020 at 17:15 JST   \n",
       "21035  September  September 9, 2020 at 17:15 JST   \n",
       "21036  September  September 9, 2020 at 17:18 JST   \n",
       "21037  September  September 9, 2020 at 19:04 JST   \n",
       "\n",
       "                                                Headline  \\\n",
       "0      Japan and Malaysia may resume travel in early ...   \n",
       "1      Japan marks 75th surrender anniversary in sole...   \n",
       "2      Indonesia to close doors to tourists until vac...   \n",
       "3      How COVID-19 has reshaped Japan's drinking cul...   \n",
       "4      COVID-19 ruins plans to spend time at the beac...   \n",
       "...                                                  ...   \n",
       "21033  China's CanSino defends coronavirus vaccine ca...   \n",
       "21034  U.S. firms in China increasingly fear bilatera...   \n",
       "21035  South Korea president to hold emergency meetin...   \n",
       "21036  Tokyo in July sees more people moving out than...   \n",
       "21037  A year after Typhoon No. 15, Chiba residents s...   \n",
       "\n",
       "                                          Headline_Clean  Sentiment  \n",
       "0      japan malaysia may resume travel early septemb...          1  \n",
       "1      japan mark surrender anniversary solemn ceremo...          1  \n",
       "2            indonesia close doors tourists vaccine find          0  \n",
       "3                            reshape japan drink culture          1  \n",
       "4                ruin plan spend time beach among things          0  \n",
       "...                                                  ...        ...  \n",
       "21033  china cansino defend coronavirus vaccine candi...          0  \n",
       "21034  firm china increasingly fear bilateral tension...          0  \n",
       "21035  south korea president hold emergency meet thur...          0  \n",
       "21036               tokyo july see people move due virus          0  \n",
       "21037     year typhoon no chiba residents still struggle          0  \n",
       "\n",
       "[21038 rows x 5 columns]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "output=df[['Month','Date','Headline','Headline_Clean','Sentiment']]\n",
    "output.to_csv(\"Japan_Headline_Clean_Covid-19_BERT_90.csv\",index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
